{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook reports the speed for both LID estimation and density estimation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe76e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python311.zip', '/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11', '/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/lib-dynload', '', '/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages', '/BS/data_mani_compress/work/thesis/thesis/external/guided-diffusion', '/BS/data_mani_compress/work/thesis/thesis/external/DenseFlow', '/BS/data_mani_compress/work/thesis/thesis']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF16 enabled: True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# add the parent directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../..\"))   # one level up from notebook/\n",
    "print(sys.path)\n",
    "from data.utils.dataloaders import get_imagenet_dataloader\n",
    "import numpy as np\n",
    "import torch\n",
    "from flextok.flextok_wrapper import FlexTokFromHub\n",
    "from flextok.utils.misc import detect_bf16_support, get_bf16_context, get_generator\n",
    "from flextok.utils.demo import imgs_from_urls, denormalize, batch_to_pil\n",
    "from LID.fokker_planck_estimator import RectifiedFlowLIDEstimator\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import time\n",
    "\n",
    "# Detect if bf16 is enabled or not\n",
    "enable_bf16 = detect_bf16_support()\n",
    "print('BF16 enabled:', enable_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6f8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a FlexTok d18-d28 model trained on DFN from HuggingFace Hub\n",
    "flextok = FlexTokFromHub.from_pretrained('EPFL-VILAB/flextok_d18_d18_in1k').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f0e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: vae | Params: 83,821,011 | Size: 319.75 MB (0.312 GB)\n",
      "Module: encoder | Params: 287,326,086 | Size: 1096.06 MB (1.070 GB)\n",
      "Module: decoder | Params: 578,587,456 | Size: 2207.14 MB (2.155 GB)\n",
      "Module: regularizer | Params: 0 | Size: 0.00 MB (0.000 GB)\n",
      "Module: flow_matching_noise_module | Params: 0 | Size: 0.00 MB (0.000 GB)\n",
      "------------------------------------------------------------\n",
      "TOTAL | Params: 949,734,553 | Size: 3622.95 MB (3.538 GB)\n"
     ]
    }
   ],
   "source": [
    "flextok.count_params_and_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de180289",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_estimator = RectifiedFlowLIDEstimator(ambient_dim=65536, model=flextok, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forward pass time per sample: 0.269512 seconds for batch size 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m50\u001b[39m):\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m get_bf16_context(enable_bf16):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m             _ = \u001b[43mlid_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_input_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_hyper\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.36\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhutchinson_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_ids_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_ids_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m torch.cuda.synchronize()\n\u001b[32m     33\u001b[39m end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/LID/fokker_planck_estimator.py:211\u001b[39m, in \u001b[36mRectifiedFlowLIDEstimator.estimate\u001b[39m\u001b[34m(self, x0, t_hyper, token_ids_list, hutchinson_samples)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m#data_dict = copy.deepcopy(data_dict)\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# 1) forward pass without grad until the step before the last. \u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_bf16_context(\u001b[38;5;28mself\u001b[39m.enable_bf16):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     data_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_pass_until_t_hyper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_hyper\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# your Euler loop\u001b[39;00m\n\u001b[32m    213\u001b[39m     div, norm = \u001b[38;5;28mself\u001b[39m.model.pipeline.forward_pass_at_t_hyper(data_dict, t_hyper)\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# choose scaling; simplest is just combine them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/flow_matching/pipelines.py:217\u001b[39m, in \u001b[36mMinRFPipeline.forward_pass_until_t_hyper\u001b[39m\u001b[34m(self, data_dict, t_hyper, timesteps)\u001b[39m\n\u001b[32m    214\u001b[39m data_dict[\u001b[38;5;28mself\u001b[39m.timesteps_read_key] = t_vec\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Single forward pass; the model writes its prediction under reconst_write_key\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m out_dd = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.reconst_write_key]\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[32m    220\u001b[39m     latents[j].add_(out_dd[j], alpha=dt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/utils/wrappers.py:44\u001b[39m, in \u001b[36mSequentialModuleDictWrapper.forward\u001b[39m\u001b[34m(self, data_dict)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module_dict.values():\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         data_dict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/trunks/transformers.py:205\u001b[39m, in \u001b[36mFlexTransformer.forward\u001b[39m\u001b[34m(self, data_dict)\u001b[39m\n\u001b[32m    202\u001b[39m intermediate_layers = []\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.blocks):\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_mod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_mod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43madaLN_emb\u001b[49m\u001b[43m=\u001b[49m\u001b[43madaLN_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43madaLN_packing_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43madaLN_packing_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_forward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_forward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.intermediate_layers:\n\u001b[32m    214\u001b[39m         intermediate_layers.append(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/layers/transformer_blocks.py:147\u001b[39m, in \u001b[36mFlexBlockAdaLN.forward\u001b[39m\u001b[34m(self, x, score_mod, block_mask, adaLN_emb, adaLN_packing_fn, rope_forward, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m adaLN_emb_packed = expand_to_padded_seq(adaLN_emb_packed, x)\n\u001b[32m    141\u001b[39m gate_msa, gate_mlp, shift_msa, scale_msa, shift_mlp, scale_mlp = adaLN_emb_packed.chunk(\n\u001b[32m    142\u001b[39m     \u001b[32m6\u001b[39m, dim=-\u001b[32m1\u001b[39m\n\u001b[32m    143\u001b[39m )\n\u001b[32m    145\u001b[39m x = x + gate_msa * \u001b[38;5;28mself\u001b[39m.drop_path(\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.attn(\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         modulate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, shift_msa, scale_msa),\n\u001b[32m    148\u001b[39m         score_mod=score_mod,\n\u001b[32m    149\u001b[39m         block_mask=block_mask,\n\u001b[32m    150\u001b[39m         rope_forward=rope_forward,\n\u001b[32m    151\u001b[39m     )\n\u001b[32m    152\u001b[39m )\n\u001b[32m    153\u001b[39m x = x + gate_mlp * \u001b[38;5;28mself\u001b[39m.drop_path(\u001b[38;5;28mself\u001b[39m.mlp(modulate(\u001b[38;5;28mself\u001b[39m.norm2(x), shift_mlp, scale_mlp)))\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/layers/norm.py:19\u001b[39m, in \u001b[36mFp32LayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     output = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output.type_as(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/functional.py:2900\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2891\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2892\u001b[39m         layer_norm,\n\u001b[32m   2893\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2898\u001b[39m         eps=eps,\n\u001b[32m   2899\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2900\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2901\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "for p in flextok.parameters():\n",
    "        p.requires_grad_(False)\n",
    "flextok.eval()\n",
    "\n",
    "batch_sizes_to_test = [4, 8, 16]\n",
    "for batch_size in batch_sizes_to_test:\n",
    "\n",
    "    # generate random torch of shape 4 256\n",
    "    random_registers = torch.randn(batch_size, 256).to(device)\n",
    "    random_input_images = torch.randn(batch_size, 3, 256, 256).to(device)\n",
    "\n",
    "    token_ids_list = [\n",
    "                torch.as_tensor(t[:1], dtype=torch.long, device=device).unsqueeze(0)\n",
    "                for t in random_registers\n",
    "            ]\n",
    "\n",
    "    # warm up\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            with get_bf16_context(enable_bf16):\n",
    "                _ = lid_estimator.estimate(random_input_images, t_hyper=0.36, hutchinson_samples=2, token_ids_list=token_ids_list)\n",
    "\n",
    "    # timing\n",
    "    torch.cuda.synchronize()  # IMPORTANT if using GPU\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(50):\n",
    "            with get_bf16_context(enable_bf16):\n",
    "                _ = lid_estimator.estimate(random_input_images, t_hyper=0.36, hutchinson_samples=2, token_ids_list=token_ids_list)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "\n",
    "    avg_time = (end - start) / 50\n",
    "    print(f\"Average forward pass time per sample: {avg_time/batch_size:.6f} seconds for batch size {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb8e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Density estimation speed test\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e562d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forward pass time per sample: 0.866637 seconds for batch size 4\n",
      "Average forward pass time per sample: 0.818155 seconds for batch size 8\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 141.50 MiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.62 GiB is allocated by PyTorch, and 630.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_bf16_context(enable_bf16):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         _,_ = \u001b[43mflextok\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_log_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_input_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhutchinson_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_ids_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_ids_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# timing\u001b[39;00m\n\u001b[32m     23\u001b[39m torch.cuda.synchronize()  \u001b[38;5;66;03m# IMPORTANT if using GPU\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/flextok_wrapper.py:208\u001b[39m, in \u001b[36mFlexTok.estimate_log_density\u001b[39m\u001b[34m(self, images, token_ids_list, guidance_scale, hutchinson_samples, verbose, conditional, timesteps)\u001b[39m\n\u001b[32m    205\u001b[39m     data_dict.update(prepared_data)\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Estimate densities using the pipeline.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m integral_part, source_part = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_log_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhutchinson_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhutchinson_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconditional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m integral_part, source_part\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/flow_matching/pipelines.py:368\u001b[39m, in \u001b[36mMinRFPipeline.estimate_log_density\u001b[39m\u001b[34m(self, data_dict, timesteps, guidance_scale, hutchinson_samples, verbose, conditional)\u001b[39m\n\u001b[32m    362\u001b[39m     dd_un[\u001b[33m\"\u001b[39m\u001b[33meval_dropout_mask\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[38;5;28;01mTrue\u001b[39;00m] * B          \u001b[38;5;66;03m# activate null‑cond\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# here we assume that the model predicts the velocity field while\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# going from data to noise\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# check time spent here: \u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m#startime = time() \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m outputs_un = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdd_un\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.reconst_write_key]\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# Convert lists → batched tensors for vectorized Hutchinson\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m#   x_b  : [B,C,H,W] (built from latents_var)\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m#   u_b  : [B,C,H,W] (built from outputs_un)\u001b[39;00m\n\u001b[32m    373\u001b[39m x_b = torch.cat(latents_var, dim=\u001b[32m0\u001b[39m)     \u001b[38;5;66;03m# graph depends on each latents_var[j]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/utils/wrappers.py:44\u001b[39m, in \u001b[36mSequentialModuleDictWrapper.forward\u001b[39m\u001b[34m(self, data_dict)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module_dict.values():\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         data_dict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/trunks/transformers.py:205\u001b[39m, in \u001b[36mFlexTransformer.forward\u001b[39m\u001b[34m(self, data_dict)\u001b[39m\n\u001b[32m    202\u001b[39m intermediate_layers = []\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.blocks):\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_mod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_mod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43madaLN_emb\u001b[49m\u001b[43m=\u001b[49m\u001b[43madaLN_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43madaLN_packing_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43madaLN_packing_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_forward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_forward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.intermediate_layers:\n\u001b[32m    214\u001b[39m         intermediate_layers.append(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/miniforge3/envs/dgm_geometry/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/layers/transformer_blocks.py:139\u001b[39m, in \u001b[36mFlexBlockAdaLN.forward\u001b[39m\u001b[34m(self, x, score_mod, block_mask, adaLN_emb, adaLN_packing_fn, rope_forward, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    130\u001b[39m     x,\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# Embed and expand adaLN_embs: B x (exp*6*D) -> sum(N_i) x (6*D)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     adaLN_emb_packed = \u001b[43madaLN_packing_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madaLN_modulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43madaLN_emb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m     adaLN_emb_packed = expand_to_padded_seq(adaLN_emb_packed, x)\n\u001b[32m    141\u001b[39m     gate_msa, gate_mlp, shift_msa, scale_msa, shift_mlp, scale_mlp = adaLN_emb_packed.chunk(\n\u001b[32m    142\u001b[39m         \u001b[32m6\u001b[39m, dim=-\u001b[32m1\u001b[39m\n\u001b[32m    143\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/BS/data_mani_compress/work/thesis/thesis/external/flextok/flextok/model/preprocessors/flex_seq_packing.py:144\u001b[39m, in \u001b[36mexpand_emb_per_subseq\u001b[39m\u001b[34m(emb_packed, packed_shapes_list)\u001b[39m\n\u001b[32m    141\u001b[39m repeats_flat = repeats.flatten()  \u001b[38;5;66;03m# Shape: [b * n]\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Repeat embeddings according to repeats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m emb_expanded_flat = \u001b[43memb_packed_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeats_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Return the expanded embeddings\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m emb_expanded_flat.unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 141.50 MiB is free. Including non-PyTorch memory, this process has 22.55 GiB memory in use. Of the allocated memory 21.62 GiB is allocated by PyTorch, and 630.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "for p in flextok.parameters():\n",
    "        p.requires_grad_(False)\n",
    "flextok.eval()\n",
    "\n",
    "batch_sizes_to_test = [4, 8, 16, 32]\n",
    "for batch_size in batch_sizes_to_test:\n",
    "\n",
    "    # generate random torch of shape 4 256\n",
    "    random_registers = torch.randn(batch_size, 256).to(device)\n",
    "    random_input_images = torch.randn(batch_size, 3, 256, 256).to(device)\n",
    "\n",
    "    token_ids_list = [\n",
    "                torch.as_tensor(t[:1], dtype=torch.long, device=device).unsqueeze(0)\n",
    "                for t in random_registers\n",
    "            ]\n",
    "\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        with get_bf16_context(enable_bf16):\n",
    "            _,_ = flextok.estimate_log_density(random_input_images, timesteps=25, hutchinson_samples=2, token_ids_list=token_ids_list)\n",
    "\n",
    "    # timing\n",
    "    torch.cuda.synchronize()  # IMPORTANT if using GPU\n",
    "    start = time.time()\n",
    "\n",
    "    for _ in range(50):\n",
    "        with get_bf16_context(enable_bf16):\n",
    "            _,_ = flextok.estimate_log_density(random_input_images, timesteps=25, hutchinson_samples=2, token_ids_list=token_ids_list)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "\n",
    "    avg_time = (end - start) / 50\n",
    "    print(f\"Average forward pass time per sample: {avg_time/batch_size:.6f} seconds for batch size {batch_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgm_geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

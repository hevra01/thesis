train:
  _target_: data.datasets.huggingface_dataset.HuggingFaceDataset
  #  # Wrap the HuggingFace dataset (ArrowDataset) and any PyTorch transform together in one object, 
  #  # so they can be used as a PyTorch-compatible dataset in training pipelines.
        
  #       E.g.

  #       # Load raw dataset
  #       raw_dataset = load_dataset("mnist")['train']

  #       # Define Torch transform
  #       my_transform = transforms.Compose([
  #           transforms.ToTensor(),
  #           transforms.Normalize((0.5,), (0.5,))
  #       ])

  #       # Wrap HuggingFace dataset
  #       dataset = HuggingFaceDataset(dataset=raw_dataset, transform=my_transform)
  #       

  dataset:
    # similar to datasets.load_dataset(path="mnist", split="train", trust_remote_code=True)
    _target_: datasets.load_dataset
    path: mnist # Huggingface dataset from https://huggingface.co/datasets
    split: train
    trust_remote_code: True

  transform:
    _target_: torchvision.transforms.Compose
    transforms: ${oc.dict.values:experiment.all_data_transforms}


val:
  _target_: data.datasets.huggingface_dataset.HuggingFaceDataset

  dataset:
    _target_: datasets.load_dataset
    path: mnist # Huggingface dataset from https://huggingface.co/datasets
    split: test
    trust_remote_code: True

  transform:
    _target_: torchvision.transforms.Compose
    transforms: ${oc.dict.values:experiment.all_data_transforms} 

data_dim: 784
mean: 0.1307
std: 0.3081

inverse_mean: -0.4242 # -mean/std
inverse_std: 3.2457 # 1/std
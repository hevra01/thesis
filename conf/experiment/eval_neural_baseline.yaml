defaults:
  - /model: resnet_fine_tune
  - /dataset: imageNet

dataset:
  split: val_categorized
  train_or_eval: eval

# this is for the main dataset that has the LPIPS loss for all the images for different
# values of k_values.
reconstruction_dataset:
  reconstruction_data_path: "data/datasets/imagenet_reconstruction_losses/val_categorized/all_losses.json"
  batch_size: 180 # this is the batch size for the reconstruction dataset on A40, 4 GPU, 180 batch size is possible
  shuffle: true
  num_workers: 6
  prefetch_factor: 2
  reconstruction_loss_key: "LPIPS"  # e.g., "mse_error" or "vgg_error"
  
  # in regression, we predict the actual reconstruction loss value
  # and we might either want to evaluate the performance on how well 
  # a certain recon loss range is predicted (e.g., 0.1 to 0.2)
  # or we might want to evaluate how well the recon losses that belong to a certain token count are predicted. 
  # hence, the filter key for regression can actually be either LPIPS or k_value. 
  filter_key_k_value: k_value # LPIPS or k_value


  # in classification, we predict the token count. we can evaluate the performance either 
  # based on how well a certain class is predicted or based on how well the token counts that belong to a certain
  # recon loss range are predicted. hence, the filter key for classification can actually be either LPIPS or k_value.
  filter_key_recon_loss: LPIPS # LPIPS or k_value
  
  # [0.02079272, 0.12662399, 0.23245525, 0.33828652, 0.44411778, 0.54994905, 0.65578032, 0.76161158, 0.86744285, 0.97327411, 1.07910538] uniform
  # [0.007, 0.313, 0.375, 0.422, 0.463, 0.503, 0.543, 0.583, 0.622, 0.664, 1.172] quantile
  recon_loss_ranges_recon_loss: [0.02079272, 0.12662399, 0.23245525, 0.33828652, 0.44411778, 0.54994905, 0.65578032, 0.76161158, 0.86744285, 0.97327411, 1.07910538] # [1, 1, 2, 2, 4, 4, 8, 8, 16, 16, 32, 32, 64, 64, 128, 128, 256, 256] or [0.007, 0.313, 0.375, 0.422, 0.463, 0.503, 0.543, 0.583, 0.622, 0.664, 1.172]
  recon_loss_ranges_k_value: [1, 1, 2, 2, 4, 4, 8, 8, 16, 16, 32, 32, 64, 64, 128, 128, 256, 256] # [1, 1, 2, 2, 4, 4, 8, 8, 16, 16, 32, 32, 64, 64, 128, 128, 256, 256] or [0.007, 0.313, 0.375, 0.422, 0.463, 0.503, 0.543, 0.583, 0.622, 0.664, 1.172]
  skip_range_k_value: 2 # 1 or 2
  skip_range_recon_loss: 1 # 1 or 2

device: cuda:0

filter_based_on: regression # options: classification, regression

model:
  pretrained: false
  checkpoint_path: neural_baseline/checkpoint/predict_recon_loss/all.pt
  use_condition: True
  task_type: regression  # options: classification, regression


experiment_name: eval_neural_baseline_recon_loss_prediction
project_name: neural_baselines_regression_recon_loss_prediction
group_name: eval_fine_tune_resnet_for_all_ks
# conf/model/token_count_predictor.yaml
_target_: models.neural_token_count_predictor.NeuralTokenCountPredictor

# device to run on
device: cuda      

# --- Backbone/feature extractor: can be either a CNN alone or VAE encoder & CNN---
apply_VAE_encoder: false


# --- CNN trunk (for RGB path) ---
# We define per-layer channels and strides. Stride=2 downsamples spatially.
# Example below (for 256x256 images → latents ~ [B,4,32,32]):
#   C0:  3 →  32 @ 128x128   (stride 2)
#   C1: 32 →  64 @ 64x64   (stride 2)
#   C2: 64 → 128 @  32x32   (stride 2)
conv_channels: [32, 64, 128]       # output channels for each conv block
conv_strides:  [2,   2,   2]         # stride per conv block (same length)
norm: group                                # group | batch | none
num_groups: 8                               # used if norm=group
conv_activation: silu                      # relu | gelu | silu | tanh  (don't apply classification to the last layer)
dropout2d: 0.10                            # dropout after conv blocks (2D)

# Optional pooling after the conv stack:
#   none  → keep spatial dims, then flatten
#   gap   → global average pool to [B, C], skip flatten
post_conv_pool: gap                       # none | gap


# --- Conditioning vector (tolerated loss etc.) ---
loss_dim: 1                               # size of conditioning vector
loss_proj_dim: 1                         # embed cond → this many dims


# --- Task ---
head: "classification"               # classification | regression
num_classes: 256                     # for classification: predict counts in {1..256}. for regression: predicts only 1 class


# --- Fully-connected head (classification) ---
# Applied after (flatten OR GAP) and concat with loss embedding.
fc_hidden: [512, 256]                      # MLP widths; [] means direct to logits
